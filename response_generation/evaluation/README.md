# Evaluation

We use the AutoNuggetizer framework proposed for RAG systems evaluation and validated during the TREC RAG'24 track for performance evaluation. AutoNuggetizer comprises two steps: nugget creation and nugget assignment[^1]. In nugget creation, nuggets are formulated based on relevant documents and classified as either *vital* or *okay*. The second step, nugget assignment, involves assessing whether a systemâ€™s response contains specific nuggets from the answer key. 

We use LLMs to automate the computation of the score, adhering to the original prompts from[^1]. To make the evaluation more robust and mitigate any potential bias of using the same LLM for response generation and judging, we use the average of the scores generated by three different LLMs (*gpt-4o-2024-08-06*, *claude-3-5-haiku-20241022*, *gemini-1.5-flash*) as a final score. We validate our implementation of the evaluation framework by comparing the relative ordering of systems with the official results reported by track organizers[^1].

Evaluation with AutoNuggetizer comprise three steps:
1) Nugget detection that can be run with the following command: ```python -m response_generation.evaluation.detect_nuggets --model_name {model_name}```. Model name can be one of the following: *gpt4, claude, gemini*.
2) Nugget assignment to the generated response that can be run with the following command: ```python -m response_generation.evaluation.assign_nuggets --model_name {model_name} --response_type {response_type}```. Model name can be one of the following: *gpt4, claude, gemini*. Response type can one of the following: *baseline_top_5, baseline_top_5_cot, ginger_top_5, ginger-fluency_top_5, ginger-fluency_top_10, ginger-fluency_top_20, ginger_lsa_bm25, ginger_lsa_duot5, ginger_bertopic_bm25*.
3) Calculating score for the generated responses that can be run with the following command: ```python -m response_generation.evaluation.calculate_score```

[^1]: Ronak Pradeep, Nandan Thakur, Shivani Upadhyay, Daniel Campos, Nick Craswell, and Jimmy Lin. 2024. Initial Nugget Evaluation Results for the TREC 2024 RAG Track with the AutoNuggetizer Framework. arXiv:2411.09607 [cs.IR]